{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BERT for Low-Resource Question-Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Pre-trained language representations have been shown to improve many downstream NLP tasks such as question answering and natural language inference (NLI). Devlin, Jacob, et al proposed `BERT` [1] (Bidirectional Encoder Representations from Transformers), which fine-tunes deep bi-directional representations on a wide range of tasks with minimal task-specific parameters, and obtained state-of-the-art results.\n",
    "\n",
    "In this tutorial, you will focus on adapting the `BERT` model for the question answering task on the `SQuAD` dataset. Specifically, you will:\n",
    "\n",
    "- Understand how to pre-process the `SQuAD` dataset to leverage the learnt representations in `BERT`.\n",
    "- Adapt the `BERT` model to the question-answering task.\n",
    "- Load a trained model to perform inference on the `SQuAD` dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, metric, autograd\n",
    "from mxnet.gluon.contrib import estimator\n",
    "import gluonnlp as nlp\n",
    "ctx = mx.gpu(0)\n",
    "!ulimit -n 16384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bert` module can be downloaded from the [GluonNLP BERT model zoo](https://gluon-nlp.mxnet.io/v0.9.x/model_zoo/bert/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import bert_qa_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prepare the `SQuAD` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train_original = nlp.data.SQuAD(segment='train', version='1.1')\n",
    "squad_dev = nlp.data.SQuAD(segment='dev', version='1.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of each record of the dataset is following:\n",
    "\n",
    "- record_index:  An index of the record, generated on the fly (0 ... to # of last question)\n",
    "- question_id:   Question Id. It is a string and taken from the original json file as-is\n",
    "- question:      Question text, taken from the original json file as-is\n",
    "- context:       Context text.  Will be the same for questions from the same context\n",
    "- answer_list:   All answers for this question. Stored as python list\n",
    "- start_indices: All answers' starting indices. Stored as python list.\n",
    "  The position in this list is the same as the position of an answer in answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train_original[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample for Low-resource Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDownSampler(gluon.data.Sampler):\n",
    "    def __init__(self, length, ratio):\n",
    "        self._length = length\n",
    "        self._ratio = ratio\n",
    "        self._count = int(np.round(length * ratio))\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = np.arange(self._length)\n",
    "        np.random.shuffle(indices)\n",
    "        indices = indices[:self._count]\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train = squad_train_original.sample(RandomDownSampler(len(squad_train_original), 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original # samples: {}, downsampled to # samples: {}'.format(len(squad_train_original),\n",
    "                                                                    len(squad_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Data pre-processing for QA with `BERT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:30:12.299493Z",
     "start_time": "2019-06-14T01:30:12.183419Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![qa](img/qa.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.715444Z",
     "start_time": "2019-06-14T01:45:27.569118Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bert_encoder, vocab = nlp.model.get_model('bert_12_768_12',\n",
    "                                          dataset_name='openwebtext_book_corpus_wiki_en_uncased',\n",
    "                                          use_classifier=False,\n",
    "                                          use_decoder=False,\n",
    "                                          use_pooler=False,\n",
    "                                          pretrained=True,\n",
    "                                          ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.720137Z",
     "start_time": "2019-06-14T01:45:27.717192Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Subword Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.731724Z",
     "start_time": "2019-06-14T01:45:27.721690Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = nlp.data.BERTTokenizer(vocab=vocab, lower=True)\n",
    "\n",
    "tokenizer(\"as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### QA For BERT Transformation\n",
    "\n",
    "The transformation is processed in the following steps:\n",
    "- Tokenize the question_text in the example.\n",
    "- For examples where the document is too long,\n",
    "  use a sliding window to split into multiple features and\n",
    "  record whether each token is a maximum context.\n",
    "- Tokenize the split document chunks.\n",
    "- Combine the token of question_text with the token\n",
    "  of the document and insert [CLS] and [SEP].\n",
    "- Generate the start position and end position of the answer.\n",
    "- Generate valid length.\n",
    "\n",
    "The functionality is available via the `SQuADTransform` API from BERT model zoo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_qa_transform = bert.data.qa.SQuADTransform(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dataset(dataset):\n",
    "    return gluon.data.SimpleDataset([x for xs in dataset for x in xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = flatten_dataset(squad_train.transform(bert_qa_transform))\n",
    "processed_dev = flatten_dataset(squad_dev.transform(bert_qa_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Stack(), # example ID\n",
    "    nlp.data.batchify.Pad(axis=0, pad_val=vocab[vocab.padding_token], dtype='float32'), # tokens\n",
    "    nlp.data.batchify.Pad(axis=0, pad_val=vocab[vocab.padding_token], dtype='float32'), # token types\n",
    "    nlp.data.batchify.Stack('float32'), # actual sample lengths without padding\n",
    "    nlp.data.batchify.Stack('float32'), # start positions\n",
    "    nlp.data.batchify.Stack('float32'), # end positions\n",
    "    nlp.data.batchify.Stack('float32')) # batch length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = mx.gluon.data.DataLoader(\n",
    "    processed_train, batchify_fn=batchify_fn,\n",
    "    batch_size=8, num_workers=4, shuffle=True)\n",
    "dev_dataloader = mx.gluon.data.DataLoader(\n",
    "    processed_dev, batchify_fn=batchify_fn,\n",
    "    batch_size=8, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining the model\n",
    "\n",
    "After the data is processed, you can define the model that uses the representation produced by BERT for predicting the starting and ending positions of the answer span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.921076Z",
     "start_time": "2019-06-14T01:45:27.912650Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class BertForQA(mx.gluon.HybridBlock):\n",
    "    def __init__(self, bert_encoder, prefix=None, params=None):\n",
    "        super(BertForQA, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert_encoder\n",
    "        with self.name_scope():\n",
    "            self.span_classifier = mx.gluon.nn.Dense(units=2, flatten=False)\n",
    "\n",
    "    def hybrid_forward(self, F, inputs, token_types, valid_length=None):\n",
    "        # Use self.bert to get the representation for each token.\n",
    "        bert_output = self.bert(inputs, token_types, valid_length)\n",
    "        \n",
    "        # Use self.span_classifier to predict the start and end spans\n",
    "        return self.span_classifier(bert_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now download a BERT model trained on the SQuAD dataset, and prepare the `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:32.221383Z",
     "start_time": "2019-06-14T01:45:27.922825Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net = BertForQA(bert_encoder)\n",
    "net.span_classifier.initialize(ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in net.collect_params('.*beta|.*gamma|.*bias').values():\n",
    "    p.wd_mult = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnable_params = [p for p in net.collect_params().values() if p.grad_req != 'null']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "warmup_ratio = 0.1\n",
    "num_train_steps = epochs * len(train_dataloader)\n",
    "num_warmup_steps = int(num_train_steps * warmup_ratio)\n",
    "lr = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'adam',\n",
    "                        {'learning_rate': lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "lr_handler = utils.MyLearningRateHandler(trainer, num_warmup_steps, num_train_steps, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [metric.Loss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAEstimator(estimator.Estimator):\n",
    "    def fit_batch(self, train_batch, batch_axis=0):\n",
    "        _, data, token_types, valid_length, start_label, end_label, _ = train_batch\n",
    "        label = mx.nd.stack(start_label, end_label, axis=1)\n",
    "\n",
    "        with autograd.record():\n",
    "            pred = self.net(data.as_in_context(ctx),\n",
    "                            token_types.as_in_context(ctx),\n",
    "                            valid_length.as_in_context(ctx))\n",
    "            pred = pred.transpose((0, 2, 1))\n",
    "            loss = self.loss(pred, label.as_in_context(ctx))\n",
    "\n",
    "        loss.backward()\n",
    "        nlp.utils.clip_grad_global_norm(learnable_params, 1)\n",
    "\n",
    "        self.trainer.step(1)\n",
    "\n",
    "        return data, label, pred, loss\n",
    "    \n",
    "    def evaluate_batch(self,\n",
    "                       val_batch,\n",
    "                       val_metrics,\n",
    "                       batch_axis=0):\n",
    "        _, data, token_types, valid_length, start_label, end_label, _ = val_batch\n",
    "        label = mx.nd.stack(start_label, end_label, axis=1)\n",
    "        pred = self.net(data.as_in_context(ctx),\n",
    "                        token_types.as_in_context(ctx),\n",
    "                        valid_length.as_in_context(ctx))\n",
    "        pred = pred.transpose((0, 2, 1))\n",
    "        loss = self.loss(pred, label.as_in_context(ctx))\n",
    "        # update metrics\n",
    "        for m in val_metrics:\n",
    "            if isinstance(m, metric.Loss):\n",
    "                m.update(0, loss)\n",
    "            else:\n",
    "                m.update(label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = QAEstimator(net=net, loss=loss,\n",
    "                  metrics=metrics,\n",
    "                  trainer=trainer,\n",
    "                  context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "est.fit(train_data=train_dataloader,\n",
    "        epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = [metric.Loss()]\n",
    "est.evaluate(val_data=dev_dataloader,\n",
    "             val_metrics=val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics[0].get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And lastly, take a look at the predictions your model can make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, dataset, dev_dataloader, vocab):\n",
    "    tokenizer = nlp.data.BERTTokenizer(vocab=vocab, lower=True)\n",
    "    transform = bert.data.qa.SQuADTransform(tokenizer, is_pad=False,\n",
    "                                            is_training=False, do_lookup=False,\n",
    "                                            return_fields=False)\n",
    "    dev_dataset = dataset.transform(transform)\n",
    "    \n",
    "    all_results = []\n",
    "\n",
    "    for data in dev_dataloader:\n",
    "        example_ids, inputs, token_types, valid_length, _, _, _ = data\n",
    "        output = net(inputs.as_in_context(ctx),\n",
    "                     token_types.as_in_context(ctx),\n",
    "                     valid_length.as_in_context(ctx))\n",
    "        pred_start, pred_end = mx.nd.split(output, axis=2, num_outputs=2)\n",
    "\n",
    "        batch_size = example_ids.shape[0]\n",
    "        all_results.append((example_ids.asnumpy().tolist(),\n",
    "                            pred_start.reshape(batch_size, -1).asnumpy(),\n",
    "                            pred_end.reshape(batch_size, -1).asnumpy()))\n",
    "\n",
    "    all_results_np = collections.defaultdict(list)\n",
    "    for example_ids, pred_start, pred_end in all_results:\n",
    "        for example_id, start, end in zip(example_ids, pred_start, pred_end):\n",
    "            all_results_np[example_id].append(\n",
    "                bert_qa_evaluate.PredResult(start=start, end=end))\n",
    "\n",
    "    all_predictions = collections.OrderedDict()\n",
    "    top_results = []\n",
    "    for features in dev_dataset:\n",
    "        results = all_results_np[features[0].example_id]\n",
    "\n",
    "        prediction, nbest = bert_qa_evaluate.predict(\n",
    "            features=features,\n",
    "            results=results,\n",
    "            tokenizer=nlp.data.BERTBasicTokenizer(lower=True))\n",
    "        qas_id = features[0].qas_id\n",
    "        all_predictions[qas_id] = prediction\n",
    "        curr_result = {}\n",
    "        question = features[0].input_ids.index('[SEP]')\n",
    "        curr_result['context'] = features[0].doc_tokens\n",
    "        curr_result['question'] = features[0].input_ids[1:question]\n",
    "        curr_result['prediction'] = nbest[0]\n",
    "        top_results.append(curr_result)\n",
    "    return top_results, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:32.623482Z",
     "start_time": "2019-06-14T01:45:32.578002Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "top_results, all_predictions = predict(net, squad_dev, dev_dataloader, vocab)\n",
    "first_sample_result = top_results[0]\n",
    "print('Question: %s\\n'%(' '.join((first_sample_result['question']))))\n",
    "print('Top prediction: %.2f%% \\t %s'%(first_sample_result['prediction'][1] * 100, first_sample_result['prediction'][0]))\n",
    "print('\\nContext: %s\\n'%(' '.join(first_sample_result['context'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_qa_evaluate.get_F1_EM(squad_dev, all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: even lower resources\n",
    "\n",
    "It is impressive that with just 1/10 of the SQuAD training dataset, the finetuned BERT model can already perform reasonably well. Here's the challenge: can you devise a way to use even less data, but still achieve `f1 > 80`?\n",
    "\n",
    "Implement your idea in the form of a dataset sampler below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySampler(gluon.data.Sampler):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sampler = MySampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_squad_train = squad_train_original.sample(my_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_processed_train = flatten_dataset(new_squad_train.transform(bert_qa_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_dataloader = mx.gluon.data.DataLoader(\n",
    "    new_processed_train, batchify_fn=batchify_fn,\n",
    "    batch_size=8, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(train_data=new_train_dataloader,\n",
    "        epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.evaluate(val_data=dev_dataloader,\n",
    "             val_metrics=val_metrics)\n",
    "val_metrics[0].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, all_predictions = predict(net, squad_dev, dev_dataloader, vocab)\n",
    "bert_qa_evaluate.get_F1_EM(squad_dev, all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: out of domain QA\n",
    "\n",
    "The possibility of getting a reasonable QA model from low resource suggests the potential power of generalization. One might ask: how well can it perform on a dataset that's out of domain?\n",
    "\n",
    "In this exercise, you will implement the logic to load a dataset from the MRQA 2019 Shared Task. These datasets follow the same format as SQuAD. We will evaluate our 1/10 model on one of such dataset to answer the above question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset should return the following fields, the same as the SQuAD 1.1 dataset:\n",
    "\n",
    "- record_index:  An index of the record, generated on the fly (0 ... to # of last question)\n",
    "- question_id:   Question Id. It is a string and taken from the original json file as-is\n",
    "- question:      Question text, taken from the original json file as-is\n",
    "- context:       Context text.  Will be the same for questions from the same context\n",
    "- answer_list:   All answers for this question. Stored as python list\n",
    "- start_indices: All answers' starting indices. Stored as python list.\n",
    "  The position in this list is the same as the position of an answer in answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(gluon.data.Dataset):\n",
    "    def __getitem__(self, idx):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dev = MyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_processed_dev = flatten_dataset(new_dev.transform(bert_qa_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dev_dataloader = mx.gluon.data.DataLoader(\n",
    "    new_processed_dev, batchify_fn=batchify_fn,\n",
    "    batch_size=8, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.evaluate(val_data=new_dev_dataloader,\n",
    "             val_metrics=val_metrics)\n",
    "val_metrics[0].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, all_predictions = predict(net, new_processed_dev, new_dev_dataloader, vocab)\n",
    "bert_qa_evaluate.get_F1_EM(new_processed_dev, all_predictions)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
